{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-30-18-53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "_g = globals()\n",
    "\n",
    "pd.options.display.max_rows = 200000\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "now = dt.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "result_dir = f'results/{now}/'\n",
    "print(now)\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer(x):\n",
    "    print(f'{x}\\n-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = True\n",
    "prod_data = ['d_items', 'chartevents', 'admissions', 'prescriptions', \n",
    "             'diagnoses_icd', 'd_icd_diagnoses', 'patients', 'icustays', 'cptevents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dev_data(table_name):\n",
    "    datadir = 'demo-data/'\n",
    "    fname = table_name + '.csv'\n",
    "        \n",
    "    data = pd.read_csv(f'data/{fname}', dtype=str, encoding='latin1')\n",
    "    print(table_name, data.shape)\n",
    "    _g[table_name] = data\n",
    "    \n",
    "def read_prod_data(table_name):\n",
    "    datadir = 'data/'\n",
    "    fname = table_name.upper() + '.csv.gz'\n",
    "\n",
    "    data = pd.read_csv(f'data/{fname}', dtype=str, encoding='latin1', \n",
    "                       compression='gzip')\n",
    "    data.columns = [x.lower() for x in data.columns]\n",
    "    print(table_name, data.shape)\n",
    "    _g[table_name] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not prod:\n",
    "    datadir = 'demo-data/'\n",
    "    for fname in [x for x in os.listdir(datadir) if '.csv' in x]:    \n",
    "        compression = 'gzip' if 'gz' in fname else 'infer'\n",
    "        trim_size = -7 if 'gz' in fname else -4\n",
    "\n",
    "        if prod:\n",
    "            if fname[:trim_size].lower() not in prod_data:\n",
    "                continue\n",
    "\n",
    "        data = pd.read_csv(f'data/{fname}', dtype=str, \n",
    "                           encoding='latin1', compression=compression)\n",
    "        fname = fname[:trim_size].lower()\n",
    "        print(fname, data.shape)\n",
    "        _g[fname] = data\n",
    "   \n",
    "# also read in the crosswalk to make the label\n",
    "icd2hccxw2014 = pd.read_csv('code_descriptions/icd2hccxw2014.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Labeled DataFrame**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnoses_icd (651047, 5)\n",
      "admissions (58976, 19)\n",
      "d_icd_diagnoses (14567, 4)\n"
     ]
    }
   ],
   "source": [
    "read_prod_data('diagnoses_icd')\n",
    "read_prod_data('admissions')\n",
    "read_prod_data('d_icd_diagnoses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hcc_cd_135</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>119057</td>\n",
       "      <td>79760</td>\n",
       "      <td>0</td>\n",
       "      <td>2155-03-31 13:30:00</td>\n",
       "      <td>2155-05-30 17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30586</td>\n",
       "      <td>151844</td>\n",
       "      <td>76803</td>\n",
       "      <td>0</td>\n",
       "      <td>2165-01-08 09:45:00</td>\n",
       "      <td>2165-01-14 13:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>100522</td>\n",
       "      <td>18982</td>\n",
       "      <td>1</td>\n",
       "      <td>2139-07-22 06:56:00</td>\n",
       "      <td>2139-08-06 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16718</td>\n",
       "      <td>128271</td>\n",
       "      <td>78536</td>\n",
       "      <td>0</td>\n",
       "      <td>2101-04-17 21:08:00</td>\n",
       "      <td>2101-04-20 20:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51975</td>\n",
       "      <td>188127</td>\n",
       "      <td>15388</td>\n",
       "      <td>0</td>\n",
       "      <td>2123-06-17 11:58:00</td>\n",
       "      <td>2123-06-21 14:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id subject_id  hcc_cd_135           admittime           dischtime\n",
       "11311  119057      79760           0 2155-03-31 13:30:00 2155-05-30 17:30:00\n",
       "30586  151844      76803           0 2165-01-08 09:45:00 2165-01-14 13:20:00\n",
       "316    100522      18982           1 2139-07-22 06:56:00 2139-08-06 12:00:00\n",
       "16718  128271      78536           0 2101-04-17 21:08:00 2101-04-20 20:30:00\n",
       "51975  188127      15388           0 2123-06-17 11:58:00 2123-06-21 14:00:00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(58976, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    0.806328\n",
       "1    0.193672\n",
       "Name: hcc_cd_135, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_aki_hcc_label(diagnoses, icdxw, d_icd_diagnoses, admissions):\n",
    "    \"\"\"take the diagnoses dataframe and create the beginning of \n",
    "    a labeled dataset\"\"\"\n",
    "    merged = pd.merge(diagnoses, icdxw, how='left', \n",
    "                      left_on='icd9_code', right_on='icd', \n",
    "                      indicator='_hcc_merge', validate='m:1')\n",
    "    \n",
    "    # pull out the diagnoses codes that don't map to an hcc (may be useful)\n",
    "    not_merged = merged.loc[merged._hcc_merge == 'left_only']\n",
    "    not_merged = not_merged.merge(d_icd_diagnoses, how='left', on='icd9_code')\n",
    "    not_merged.short_title.value_counts().to_csv(result_dir + \n",
    "                                                 'unmerged_diagnosis_to_hcc.csv', \n",
    "                                                 header=True)\n",
    "            \n",
    "    # remove them from df and make final labeled dataframe\n",
    "    merged = pd.concat([merged, \n",
    "                        pd.get_dummies(merged.hcc, prefix='hcc_cd')], axis=1)\n",
    "    cols = [x for x in merged if 'hcc_cd' in x]\n",
    "    data = merged.groupby(['hadm_id', 'subject_id'], as_index=False)[cols].max()\n",
    "    \n",
    "    def statistics_on_hcc_labels(df):\n",
    "        data = pd.concat([df.describe().T, \n",
    "               df.drop(['hadm_id', 'subject_id'], axis=1).sum()], axis=1)\\\n",
    "                .rename(columns={0:'sum'})\\\n",
    "                .sort_values('mean', ascending=False)\n",
    "        print(data.shape)\n",
    "        data.to_csv(result_dir + 'most_coded_hccs.csv')\n",
    "    \n",
    "    statistics_on_hcc_labels(data)\n",
    "    \n",
    "    drop_cols = [x for x in cols if '_135' not in x]\n",
    "    data = data.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # merge in admissions\n",
    "    data = data.merge(admissions[['hadm_id', 'subject_id', \n",
    "                                  'admittime', 'dischtime']], \n",
    "                      how='left', on=['hadm_id', 'subject_id'])\n",
    "    \n",
    "    # trasnform datatypes\n",
    "    for i in [x for x in data if 'time' in x]:\n",
    "        data[i] = pd.to_datetime(data[i])\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "df = add_aki_hcc_label(diagnoses_icd, icd2hccxw2014, \n",
    "                       d_icd_diagnoses, admissions)\n",
    "df.sample(5)\n",
    "df.shape\n",
    "df.hcc_cd_135.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d_icd_diagnoses\n",
    "del icd2hccxw2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Charts Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_prod_data('chartevents')\n",
    "read_prod_data('d_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clean_charts_data(chartevents, d_items, label):\n",
    "\n",
    "    # merge in labels\n",
    "    charts = chartevents.merge(d_items, how='left', on='itemid', indicator='_d_items')\n",
    "    f'charts data shape: {charts.shape}'\n",
    "    \n",
    "    if (charts._d_items != 'both').any():\n",
    "        print('merge statistics')\n",
    "        charts._d_items.value_counts()\n",
    "\n",
    "    # convert time fields to datetime\n",
    "    for col in ['charttime', 'storetime']:\n",
    "        charts[col] = pd.to_datetime(charts[col])\n",
    "\n",
    "    # use the earliest time between events that are recorded directly in the chart\n",
    "    # and events that are manually stored\n",
    "    charts['eventtime'] = charts[['charttime', 'storetime']].min(axis=1)\n",
    "    \n",
    "    # change the valuenum field to numeric in case we need it\n",
    "    charts['valuenum'] = charts['valuenum'].astype(float)\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    drop_cols = ['conceptid', 'param_type', '_d_items', 'valueuom', 'warning',\n",
    "                'error', 'resultstatus', 'stopped', 'row_id_x', 'row_id_y',\n",
    "                'linksto']\n",
    "    charts = charts.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # make this upper case to avoid issues with spelling and capitalization\n",
    "    charts['category'] = charts['category'].str.lower()\\\n",
    "                                            .str.replace('-', '')\\\n",
    "                                            .str.replace('  ', '')\\\n",
    "                                            .str.replace(' ', '_')\\\n",
    "                                            .str.replace(r\"\\'s\", '')\\\n",
    "                                            .str.replace('\\/', '_')\\\n",
    "                                            .str.replace('(', '')\\\n",
    "                                            .str.replace(')', '')\n",
    "    charts['category'] = charts['category']\n",
    "    \n",
    "    # merge in label\n",
    "    charts = charts.merge(label, how='left', on=['subject_id', 'hadm_id'])\n",
    "    return charts\n",
    "\n",
    "charts = make_clean_charts_data(chartevents, d_items, df)\n",
    "charts.shape\n",
    "charts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chartevents\n",
    "del d_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Investigation List**\n",
    "---\n",
    "- chronic liver disease\n",
    "- sepsis\n",
    "- mechanical ventilation\n",
    "- anemia\n",
    "- potassium\n",
    "- sodium\n",
    "\n",
    "**Done**\n",
    "- medical imaging that uses contrast dyes\n",
    "- prescriptions which can be nephrotoxins\n",
    "- low blood ph\n",
    "- hypertension\n",
    "- hematocrit\n",
    "- gender\n",
    "- age\n",
    "- ethnicity\n",
    "- creatinine increases\n",
    "- urine color\n",
    "- urine appearance\n",
    "- prior admission in 30, 60, 90, 120 days\n",
    "- prior micu icustay in 30 days\n",
    "- prior ccu icustay in 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Discovery**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrast_imaging_feature(cptevents):\n",
    "    \"\"\"cpt codes for imaging with contrast dyes\"\"\"\n",
    "    res = cptevents.loc[cptevents.cpt_cd.str.startswith('70') | \n",
    "                        cptevents.cpt_cd.str.startswith('71') |\n",
    "                        cptevents.cpt_cd.str.startswith('72') |\n",
    "                        cptevents.cpt_cd.str.startswith('73') |\n",
    "                        cptevents.cpt_cd.str.startswith('74') |\n",
    "                        cptevents.cpt_cd.str.startswith('75')]\n",
    "    radiology_cpt_codes = [\n",
    "        '74177',\n",
    "        '74160',\n",
    "        '71260',\n",
    "        '74177',\n",
    "        '73701',\n",
    "        '73201',\n",
    "        '70460',\n",
    "        '70487',\n",
    "        '70491',\n",
    "        '70481',\n",
    "        '72193',\n",
    "        '72126',\n",
    "        '72132',\n",
    "        '72129',\n",
    "        '75574',\n",
    "        '75572',\n",
    "        '70545',\n",
    "        '70548'\n",
    "    ] # codes with contrast from 2019 (i know it's not the right year)\n",
    "\n",
    "    res['ft_contrast_imaging'] = res.cpt_cd.isin(radiology_cpt_codes)*1\n",
    "    return res.groupby('hadm_id', as_index=False)['ft_contrast_imaging'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nephrotoxin_features(prescriptions, admissions):\n",
    "    \"\"\"add features for some drugs\"\"\"\n",
    "    res = prescriptions.merge(admissions, how='left', on=['hadm_id', 'subject_id'])\n",
    "    meds_list = {}\n",
    "    meds_list['antibiotics'] = ['bacitracin', \n",
    "                                'vancomycin', \n",
    "                                'amphotericin', \n",
    "                                'cephalosporin', \n",
    "                                'aminoglycoloside',\n",
    "                                'ciprofloxacin']\n",
    "    meds_list['blood_pressure'] = ['lisinopril', \n",
    "                                   'ramipril', \n",
    "                                   'metoprolol', \n",
    "                                   'candesartan', \n",
    "                                   'valsartan', \n",
    "                                   'warfarin']\n",
    "    meds_list['edema'] = ['furosemide']\n",
    "    meds_list['nsaid'] = ['ibuprofen', 'naproxen', 'ketoprofen']\n",
    "    meds_list['ulcer'] = ['cimetidine']\n",
    "    meds_list['other'] = ['propofol']\n",
    "\n",
    "    res['time_delta'] = pd.to_datetime(res.startdate) - pd.to_datetime(res.admittime)\n",
    "    def within_x_hours(data, x):\n",
    "        return data.time_delta < pd.Timedelta(x, 'hr')\n",
    "\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    # all drugs\n",
    "    drug = pd.Series([False for i in range(len(res))])\n",
    "    for med in flatten(list(meds_list.values())):\n",
    "        drug |= res.drug.str.lower().str.contains(med, na=False)\n",
    "\n",
    "    res['ft_any_nephrotoxin_rx'] = drug*1\n",
    "    for hr in [24, 48, 72]:\n",
    "        res[f'ft_any_nephrotoxin_rx_within_{hr}'] = (drug & within_x_hours(res, hr))*1\n",
    "\n",
    "    # groups of drugs\n",
    "    for group, drugs in meds_list.items():\n",
    "        drug = pd.Series([False for i in range(len(res))])\n",
    "        for med in drugs:\n",
    "            this_drug = res.drug.str.lower().str.contains(med, na=False)\n",
    "            drug |= this_drug        # add to the large list\n",
    "            res[f'ft_nephrotoxin_{med}_rx'] = this_drug*1  # make its own feature\n",
    "            for hr in [24, 48, 72]:\n",
    "                res[f'ft_nephrotoxin_{med}_rx_within_{hr}'] = (this_drug & within_x_hours(res, hr))*1\n",
    "\n",
    "        # any drug in the group\n",
    "        res[f'ft_nephrotoxin_{group}_rx'] = drug*1\n",
    "        for hr in [24, 48, 72]:\n",
    "            res[f'ft_nephrotoxin_{group}_rx_within_{hr}'] = (drug & within_x_hours(res, hr))*1\n",
    "\n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prior_admissions(admissions, icustays):\n",
    "    \"\"\"prior admissions\"\"\"\n",
    "    # self merge\n",
    "    res = admissions.merge(admissions, how='left', on=['subject_id'], suffixes=['_first', '_second'])\n",
    "    \n",
    "    # change the datatypes\n",
    "    times = [x for x in res if 'time' in x]\n",
    "    for i in times:\n",
    "        res[i] = pd.to_datetime(res[i])\n",
    "    \n",
    "    # remove comparison with self\n",
    "    res = res.loc[res.hadm_id_first != res.hadm_id_second]\n",
    "    res = res.rename(columns={'hadm_id_first': 'hadm_id'})\n",
    "    \n",
    "    # add icu data\n",
    "    res = res.merge(icustays, how='left', left_on='hadm_id_second', right_on='hadm_id', suffixes=['', '_icu'])\n",
    "    res = pd.concat([res, pd.get_dummies(res.last_careunit.str.lower(), dtype=bool)], axis=1)\n",
    "    \n",
    "    # make features\n",
    "    prior_admission_30 = (res.admittime_second - res.dischtime_first).dt.days.lt(30)\n",
    "    prior_admission_60 = (res.admittime_second - res.dischtime_first).dt.days.lt(60)\n",
    "    prior_admission_90 = (res.admittime_second - res.dischtime_first).dt.days.lt(90)\n",
    "    prior_admission_120 = (res.admittime_second - res.dischtime_first).dt.days.lt(120)\n",
    "    \n",
    "    res['ft_prior_admission_30'] = prior_admission_30*1\n",
    "    res['ft_prior_admission_60'] = prior_admission_60*1\n",
    "    res['ft_prior_admission_90'] = prior_admission_90*1\n",
    "    res['ft_prior_admission_120'] = prior_admission_120*1\n",
    "    \n",
    "    res['ft_avg_icu_los_within_30'] = np.where(prior_admission_30, res.los.astype(float), np.nan)\n",
    "    res['ft_micu_within_30'] = (res.micu & prior_admission_30) * 1\n",
    "    res['ft_ccu_within_30'] = (res.ccu & prior_admission_30) * 1\n",
    "    \n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hcc_feature(hccs, label='', rename_as=None):\n",
    "    \"\"\"select an hcc feature\"\"\"\n",
    "    cols = [x for x in hccs if 'hcc_' in x]\n",
    "    if label:\n",
    "        drop_cols = [x for x in cols if label not in x]\n",
    "        hccs = hccs.drop(drop_cols, axis=1)\n",
    "    \n",
    "    if rename_as:\n",
    "        assert isinstance(rename_as, str)\n",
    "        hccs = hccs.rename(columns={'hcc_cd' + label: rename_as})\n",
    "    return hccs.drop('subject_id', axis=1)\n",
    "    \n",
    "def create_hcc_labeled_dataset(diagnoses, icdxw):\n",
    "    \"\"\"take the diagnoses dataframe and create the beginning of \n",
    "    a labeled dataset\"\"\"\n",
    "    merged = pd.merge(diagnoses, icdxw, how='left', \n",
    "                      left_on='icd9_code', right_on='icd', \n",
    "                      indicator='_hcc_merge', validate='m:1')\n",
    "            \n",
    "    # remove them from df and make final labeled dataframe\n",
    "    merged = pd.concat([merged, \n",
    "                        pd.get_dummies(merged.hcc, prefix='hcc_cd')], axis=1)\n",
    "    cols = [x for x in merged if 'hcc_cd' in x]\n",
    "    data = merged.groupby(['hadm_id', 'subject_id'], as_index=False)[cols].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blood_ph_features(charts):\n",
    "    \"\"\"create features for the low blood ph\"\"\"\n",
    "    res = charts.loc[charts.label.str.contains('pH') | charts.label.str.contains('PH'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                      'value', 'valuenum', 'unitname']]\n",
    "    res['label'] = 'blood_ph'\n",
    "    \n",
    "    # what is low blood ph\n",
    "    lowbloodph = res.valuenum.lt(7.30)\n",
    "    \n",
    "    res['time_delta'] = res.eventtime - res.admittime    \n",
    "    def within_x_hours(data, x):\n",
    "        return data.time_delta < pd.Timedelta(x, 'hr')\n",
    "    \n",
    "    res['ft_low_blood_ph'] = lowbloodph*1\n",
    "    res['ft_low_blood_ph_within_6_hrs'] = (lowbloodph & within_x_hours(res, 6))*1\n",
    "    res['ft_low_blood_ph_within_12_hrs'] = (lowbloodph & within_x_hours(res, 12))*1\n",
    "    res['ft_low_blood_ph_within_24_hrs'] = (lowbloodph & within_x_hours(res, 24))*1\n",
    "    res['ft_low_blood_ph_within_36_hrs'] = (lowbloodph & within_x_hours(res, 36))*1\n",
    "    res['ft_low_blood_ph_within_48_hrs'] = (lowbloodph & within_x_hours(res, 48))*1\n",
    "    \n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demographics_features(admissions, patients):\n",
    "    \"\"\"check admission information and patient demographics\"\"\"\n",
    "    pt = admissions.merge(patients, how='left', on='subject_id')\n",
    "\n",
    "    # convert data types\n",
    "    pt['dob'] = pd.to_datetime(pt.dob)\n",
    "    pt['admittime'] = pd.to_datetime(pt.admittime)\n",
    "\n",
    "    # remap gender as a binary variable\n",
    "    pt['ft_gender'] = pt.gender.map({'F': 0, 'M': 1})\n",
    "\n",
    "    # create an age feature\n",
    "    pt['ft_age'] = pt.admittime.sub(pt.dob, axis=0).dt.days / 365.25\n",
    "    pt['ft_age'] = np.where(pt.ft_age < -1, np.nan, pt.ft_age) \n",
    "    # null out fake dobs, they don't give us information\n",
    "\n",
    "    # admit type feature\n",
    "    admit_type = pd.concat([pt.hadm_id, \n",
    "                            pd.get_dummies(pt['admission_type'].str.lower(),\n",
    "                                        prefix='ft_admit_type')], axis=1)\n",
    "\n",
    "    # ethnicity feature\n",
    "    ethnicity = pd.concat([pt.hadm_id, \n",
    "                           pd.get_dummies(pt['ethnicity'].str.lower()\n",
    "                                            .str.replace('/', '_')\n",
    "                                            .str.replace(' ', '_'), \n",
    "                                            prefix='ft_race')], axis=1)\n",
    "    \n",
    "    data = pt[['hadm_id', 'ft_age', 'ft_gender']].merge(admit_type, \n",
    "                                                        how='left', on='hadm_id')\n",
    "    data = data.merge(ethnicity, how='left', on='hadm_id')\n",
    "    agg_dict = {'ft_age': 'mean', 'ft_gender': 'first'}\n",
    "    agg_dict.update({k:'max' for k in admit_type if k != 'hadm_id'})\n",
    "    agg_dict.update({k:'max' for k in ethnicity if k != 'hadm_id'})\n",
    "    \n",
    "    return data.groupby('hadm_id', as_index=False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypertensive_features(charts):\n",
    "    \"\"\"check the hypertensive status\"\"\"\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('diastolic'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                      'value', 'valuenum', 'unitname']]\n",
    "    res = res.loc[~res.label.str.lower().str.contains('unloading')] # remove the apache\n",
    "    res = res.loc[~res.label.str.lower().str.contains('pulmonary')] # remove the apache\n",
    "    res = res.loc[~res.label.str.lower().str.contains('pap')] # remove the apache\n",
    "    res.label = 'diastolic_blood_pressure'\n",
    "    \n",
    "    res2 = charts.loc[charts.label.str.lower().str.contains('systolic'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                      'value', 'valuenum', 'unitname']]\n",
    "    res2 = res2.loc[~res2.label.str.lower().str.contains('unloading')] # remove the apache\n",
    "    res2 = res2.loc[~res2.label.str.lower().str.contains('pulmonary')] # remove the apache\n",
    "    res2 = res2.loc[~res2.label.str.lower().str.contains('pap')] # remove the apache\n",
    "    res2.label = 'systolic_blood_pressure'\n",
    "    \n",
    "    # create combined events\n",
    "    data = res2.merge(res, how='outer', on=['hadm_id', 'eventtime'], indicator=True, \n",
    "                 suffixes=['_systolic', '_diastolic'])\n",
    "    data = data.loc[data._merge == 'both'].drop('_merge', axis=1)\n",
    "    \n",
    "    # delete stuff to clear memory\n",
    "    del res\n",
    "    del res2\n",
    "    \n",
    "    # make features\n",
    "    elevated = data.valuenum_systolic.between(120, 129) & data.valuenum_diastolic.lt(80)\n",
    "    hbp_stg_1 = data.valuenum_systolic.between(130, 139) | data.valuenum_diastolic.between(80, 89)\n",
    "    hbp_stg_2 = data.valuenum_systolic.between(140, 179) | data.valuenum_diastolic.between(90, 119)\n",
    "    crisis = data.valuenum_systolic.gt(180) | data.valuenum_diastolic.gt(120)\n",
    "    \n",
    "    # hours since admission\n",
    "    data['time_delta'] = data.eventtime - data.admittime_systolic\n",
    "    \n",
    "    def within_x_hours(data, x):\n",
    "        return data.time_delta < pd.Timedelta(x, 'hr')\n",
    "    \n",
    "    data['ft_elevated_bp'] = elevated*1\n",
    "    data['ft_hbp_stg_1'] = hbp_stg_1*1\n",
    "    data['ft_hbp_stg_2'] = hbp_stg_2*1\n",
    "    data['ft_hbp_crisis'] = crisis*1\n",
    "    \n",
    "    data['ft_hbp_stg_2_within_6_hours'] = (hbp_stg_2 & within_x_hours(data, 6)) * 1\n",
    "    data['ft_hbp_stg_2_within_12_hours'] = (hbp_stg_2 & within_x_hours(data, 12)) * 1\n",
    "    data['ft_hbp_stg_2_within_24_hours'] = (hbp_stg_2 & within_x_hours(data, 24)) * 1\n",
    "    data['ft_hbp_stg_2_within_36_hours'] = (hbp_stg_2 & within_x_hours(data, 36)) * 1\n",
    "    data['ft_hbp_stg_2_within_48_hours'] = (hbp_stg_2 & within_x_hours(data, 48)) * 1\n",
    "    \n",
    "    features = [x for x in data if 'ft_' in x]\n",
    "    data = data.groupby('hadm_id', as_index=False)[features].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hematocrit_features(charts, pt):\n",
    "    \"\"\" check hematocrit and hemoglobin levels for anemia \"\"\"\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('hematocrit'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', 'value', 'valuenum', 'unitname']]\n",
    "    res = res.loc[~res.label.str.lower().str.contains('apache')] # remove the apache\n",
    "\n",
    "    # add the gender\n",
    "    res = res.merge(pt[['hadm_id', 'ft_gender']], how='left', on='hadm_id')\n",
    "\n",
    "    # clean the label name\n",
    "    res['label'] = 'hematocrit'\n",
    "\n",
    "    # add features\n",
    "    male = res.ft_gender == 1\n",
    "    male_range = (42, 50)\n",
    "    female_range = (37, 47)\n",
    "    above_normal = (male & (res.valuenum > male_range[1])) | (~male & (res.valuenum > female_range[1]))\n",
    "    below_normal = (male & (res.valuenum < male_range[0])) | (~male & (res.valuenum < female_range[0]))\n",
    "    way_below_normal = res.valuenum < 20\n",
    "\n",
    "    res['ft_avg_hematocrit'] = res.valuenum\n",
    "    res['ft_above_normal_hematocrit'] = above_normal*1\n",
    "    res['ft_below_normal_hematocrit'] = below_normal*1\n",
    "    res['ft_way_below_normal_hematocrit'] = way_below_normal*1\n",
    "    res = res.drop('ft_gender', axis=1)\n",
    "    \n",
    "    agg = {'ft_avg_hematocrit': 'mean',\n",
    "          'ft_above_normal_hematocrit': 'max',\n",
    "          'ft_below_normal_hematocrit': 'max',\n",
    "          'ft_way_below_normal_hematocrit': 'max'}\n",
    "\n",
    "    return res.groupby('hadm_id', as_index=False).agg(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_creatinine_features(charts, test=False):\n",
    "\n",
    "    # make a dataframe of just creatinine data\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('creatin'), \n",
    "               ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                'value', 'valuenum', 'unitname']]\n",
    "    \n",
    "    # drop crazy values\n",
    "    res = res.loc[res.valuenum <= 11]\n",
    "    \n",
    "    # sort by hospital admission and event time\n",
    "    res = res.sort_values(['hadm_id', 'eventtime']).reset_index(drop=True)\n",
    "\n",
    "    # get the value of the old test and compare to current test\n",
    "    res['value_of_previous_test'] = np.where(\n",
    "        res.hadm_id == res.hadm_id.shift(1),\n",
    "        res.valuenum.shift(1), res.valuenum)\n",
    "    res['delta'] = res.valuenum - res.value_of_previous_test\n",
    "\n",
    "    # get time previous test was administered and compare to current time\n",
    "    res['time_of_previous_test'] = np.where(\n",
    "        res.hadm_id == res.hadm_id.shift(1), \n",
    "        res.eventtime.shift(1), res.eventtime)\n",
    "    res['delta_time'] = res.eventtime - res.time_of_previous_test\n",
    "\n",
    "    # check if time is within a certain range\n",
    "    res['within_48'] = res.delta_time <= pd.Timedelta(48, 'h')\n",
    "    res['baseline_creat'] = res.groupby('hadm_id')['valuenum'].transform('first')\n",
    "\n",
    "    # make features\n",
    "    res['ft_creatinine_increase_within_48'] = ((res.delta >= 0.3) & res.within_48)*1\n",
    "    res['ft_creatinine_increase_from_baseline'] = (res.valuenum >= 1.5*res.baseline_creat)*1\n",
    "    res['ft_baseline_creat_gt_1'] = (res.baseline_creat > 1) * 1\n",
    "    res['ft_avg_creatinine'] = res.valuenum\n",
    "\n",
    "    if test:\n",
    "        return res.loc[res.groupby('hadm_id')\\\n",
    "                       ['ft_creatinine_increase_within_48'].transform('max') == 1, \n",
    "                        ['hadm_id', 'valuenum', 'delta', 'delta_time',\n",
    "                         'baseline_creat', \n",
    "                         'ft_creatinine_increase_within_48', \n",
    "                         'ft_creatinine_increase_from_baseline',\n",
    "                         'ft_baseline_creat_gt_1']]\n",
    "    \n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features]\\\n",
    "              .agg({'ft_creatinine_increase_within_48': 'max',\n",
    "                    'ft_creatinine_increase_from_baseline': 'max',\n",
    "                    'ft_baseline_creat_gt_1': 'max',\n",
    "                    'ft_avg_creatinine': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_urine_features(charts):\n",
    "\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('urine'), \n",
    "               ['hadm_id', 'eventtime', 'admittime', 'label', 'value', 'valuenum', 'unitname']]\n",
    "\n",
    "    # clean the label column\n",
    "    res['label'] = res.label.str.replace('[', '').str.replace(']', '')\n",
    "\n",
    "    # urine color\n",
    "    label = 'Urine Color'\n",
    "    color = res.loc[res.label == label]\n",
    "    color = pd.concat([color.hadm_id, pd.get_dummies(color.value.str.lower(), \n",
    "                                                 prefix=('ft_' + label.lower().replace(' ', '_')))],\n",
    "                  axis=1)\n",
    "\n",
    "    # urine appearance\n",
    "    label = 'Urine Appearance'\n",
    "    appearance = res.loc[res.label == label]\n",
    "    appearance = pd.concat([appearance.hadm_id, pd.get_dummies(appearance.value.str.lower(), \n",
    "                                                           prefix=('ft' + label.lower().replace(' ', '_')))],\n",
    "                  axis=1)\n",
    "    \n",
    "    data = color.merge(appearance, how='left', on='hadm_id')\n",
    "    data = data.groupby('hadm_id', as_index=False)[[x for x in data if 'ft_' in x]].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Feature Creation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_features = create_demographics_features(admissions, patients)\n",
    "creatinine_features = create_creatinine_features(charts)\n",
    "urine_features = create_urine_features(charts)\n",
    "hematocrit_features = create_hematocrit_features(charts, demographic_features)\n",
    "hypertensive_feature = create_hypertensive_features(charts)\n",
    "hcc_labeled_data = create_hcc_labeled_dataset(diagnoses_icd, icd2hccxw2014)\n",
    "diabetes_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_19', rename_as='hcc_cd_19_dbtes_wo_comp')\n",
    "ckd5_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_136', rename_as='hcc_cd_136_ckd_stg_5')\n",
    "ckd4_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_137', rename_as='hcc_cd_137_ckd_stg_4')\n",
    "chf_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_85', rename_as='hcc_cd_85_chf')\n",
    "vascular_disease_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_108', rename_as='hcc_cd_108_vascular')\n",
    "prior_admission_features = create_prior_admissions(admissions, icustays)\n",
    "blood_ph_features = create_blood_ph_features(charts)\n",
    "nephrotoxin_features = add_nephrotoxin_features(prescriptions, admissions)\n",
    "contrast_imaging_feature = create_contrast_imaging_feature(cptevents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(feature_list):\n",
    "    return functools.reduce(lambda x,y: pd.merge(x,y, how='outer', on='hadm_id'), feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    df.drop(['subject_id', 'admittime', 'dischtime'], axis=1),\n",
    "    demographic_features,\n",
    "    creatinine_features,\n",
    "    urine_features,\n",
    "    hematocrit_features,\n",
    "    hypertensive_feature,\n",
    "    diabetes_hcc_feature,\n",
    "    ckd4_hcc_feature,\n",
    "    ckd5_hcc_feature,\n",
    "    chf_hcc_feature,\n",
    "    vascular_disease_hcc_feature,\n",
    "    prior_admission_features,\n",
    "    blood_ph_features,\n",
    "    nephrotoxin_features,\n",
    "    contrast_imaging_feature\n",
    "]\n",
    "\n",
    "data = merge_features(features)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
