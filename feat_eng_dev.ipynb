{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01-09-32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "_g = globals()\n",
    "\n",
    "pd.options.display.max_rows = 200000\n",
    "pd.options.display.max_columns = 500\n",
    "\n",
    "now = dt.datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "result_dir = f'results/{now}/'\n",
    "print(now)\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printer(x):\n",
    "    print(f'{x}\\n-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = False\n",
    "prod_data = ['d_items', 'chartevents', 'admissions', 'prescriptions', \n",
    "             'diagnoses_icd', 'd_icd_diagnoses', 'patients', 'icustays', 'cptevents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dev_data(fname):\n",
    "    datadir = 'demo-data/'\n",
    "    table_name = fname[:-4]\n",
    "    data = pd.read_csv(f'{datadir}{fname}', dtype=str, encoding='latin1')\n",
    "    print(table_name, data.shape)\n",
    "    _g[table_name] = data\n",
    "    \n",
    "def read_prod_data(table_name):\n",
    "    datadir = 'data/'\n",
    "    fname = table_name.upper() + '.csv.gz'\n",
    "    data = pd.read_csv(f'{datadir}{fname}', dtype=str, encoding='latin1', \n",
    "                       compression='gzip')\n",
    "    data.columns = [x.lower() for x in data.columns]\n",
    "    print(table_name, data.shape)\n",
    "    _g[table_name] = data\n",
    "    \n",
    "def read_charts_data(bin_id):\n",
    "    _g['chartevents'] = pd.read_csv(f'split-data/chartevents/bin_{bin_id}.csv', dtype=str)\n",
    "    \n",
    "bins = [hex(i)[2] + c for i in range(0, 16) for c in [hex(d)[2] for d in range(0, 16)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procedureevents_mv (753, 25)\n",
      "callout (77, 24)\n",
      "d_cpt (134, 9)\n",
      "d_items (12487, 10)\n",
      "caregivers (7567, 4)\n",
      "microbiologyevents (2003, 16)\n",
      "labevents (76074, 9)\n",
      "inputevents_cv (34799, 22)\n",
      "admissions (129, 19)\n",
      "d_labitems (753, 6)\n",
      "datetimeevents (15551, 14)\n",
      "prescriptions (10398, 19)\n",
      "procedures_icd (506, 5)\n",
      "noteevents (0, 11)\n",
      "chartevents (758355, 15)\n",
      "transfers (524, 13)\n",
      "diagnoses_icd (1761, 5)\n",
      "services (163, 6)\n",
      "drgcodes (297, 8)\n",
      "outputevents (11320, 13)\n",
      "patients (100, 8)\n",
      "d_icd_diagnoses (14567, 4)\n",
      "icustays (136, 12)\n",
      "inputevents_mv (13224, 31)\n",
      "d_icd_procedures (3882, 4)\n",
      "cptevents (1579, 12)\n"
     ]
    }
   ],
   "source": [
    "if not prod:\n",
    "    datadir = 'demo-data/'\n",
    "    for fname in [x for x in os.listdir(datadir) if '.csv' in x]:    \n",
    "        if 'icloud' in fname:\n",
    "            continue\n",
    "        read_dev_data(fname)\n",
    "\n",
    "# also read in the crosswalk to make the label\n",
    "icd2hccxw2014 = pd.read_csv('code_descriptions/icd2hccxw2014.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Labeled DataFrame**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hcc_cd_135</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>170883</td>\n",
       "      <td>10124</td>\n",
       "      <td>1</td>\n",
       "      <td>2192-04-16 20:57:00</td>\n",
       "      <td>2192-05-15 19:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>118192</td>\n",
       "      <td>41795</td>\n",
       "      <td>0</td>\n",
       "      <td>2145-09-06 08:52:00</td>\n",
       "      <td>2145-09-09 16:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>117105</td>\n",
       "      <td>42135</td>\n",
       "      <td>1</td>\n",
       "      <td>2127-10-06 21:00:00</td>\n",
       "      <td>2127-10-28 12:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>170119</td>\n",
       "      <td>10074</td>\n",
       "      <td>1</td>\n",
       "      <td>2167-02-11 22:10:00</td>\n",
       "      <td>2167-02-19 15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>165436</td>\n",
       "      <td>10119</td>\n",
       "      <td>0</td>\n",
       "      <td>2117-08-21 06:58:00</td>\n",
       "      <td>2117-08-26 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id subject_id  hcc_cd_135           admittime           dischtime\n",
       "89  170883      10124           1 2192-04-16 20:57:00 2192-05-15 19:28:00\n",
       "20  118192      41795           0 2145-09-06 08:52:00 2145-09-09 16:25:00\n",
       "19  117105      42135           1 2127-10-06 21:00:00 2127-10-28 12:50:00\n",
       "88  170119      10074           1 2167-02-11 22:10:00 2167-02-19 15:30:00\n",
       "76  165436      10119           0 2117-08-21 06:58:00 2117-08-26 13:00:00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(129, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    0.604651\n",
       "1    0.395349\n",
       "Name: hcc_cd_135, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_aki_hcc_label(diagnoses, icdxw, d_icd_diagnoses, admissions):\n",
    "    \"\"\"take the diagnoses dataframe and create the beginning of \n",
    "    a labeled dataset\"\"\"\n",
    "    merged = pd.merge(diagnoses, icdxw, how='left', \n",
    "                      left_on='icd9_code', right_on='icd', \n",
    "                      indicator='_hcc_merge', validate='m:1')\n",
    "    \n",
    "    # pull out the diagnoses codes that don't map to an hcc (may be useful)\n",
    "    not_merged = merged.loc[merged._hcc_merge == 'left_only']\n",
    "    not_merged = not_merged.merge(d_icd_diagnoses, how='left', on='icd9_code')\n",
    "    not_merged.short_title.value_counts().to_csv(result_dir + \n",
    "                                                 'unmerged_diagnosis_to_hcc.csv', \n",
    "                                                 header=True)\n",
    "            \n",
    "    # remove them from df and make final labeled dataframe\n",
    "    merged = pd.concat([merged, \n",
    "                        pd.get_dummies(merged.hcc, prefix='hcc_cd')], axis=1)\n",
    "    cols = [x for x in merged if 'hcc_cd' in x]\n",
    "    data = merged.groupby(['hadm_id', 'subject_id'], as_index=False)[cols].max()\n",
    "    \n",
    "    def statistics_on_hcc_labels(df):\n",
    "        data = pd.concat([df.describe().T, \n",
    "               df.drop(['hadm_id', 'subject_id'], axis=1).sum()], axis=1)\\\n",
    "                .rename(columns={0:'sum'})\\\n",
    "                .sort_values('mean', ascending=False)\n",
    "        print(data.shape)\n",
    "        data.to_csv(result_dir + 'most_coded_hccs.csv')\n",
    "    \n",
    "    statistics_on_hcc_labels(data)\n",
    "    \n",
    "    drop_cols = [x for x in cols if '_135' not in x]\n",
    "    data = data.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # merge in admissions\n",
    "    data = data.merge(admissions[['hadm_id', 'subject_id', \n",
    "                                  'admittime', 'dischtime']], \n",
    "                      how='left', on=['hadm_id', 'subject_id'])\n",
    "    \n",
    "    # trasnform datatypes\n",
    "    for i in [x for x in data if 'time' in x]:\n",
    "        data[i] = pd.to_datetime(data[i])\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "df = add_aki_hcc_label(diagnoses_icd, icd2hccxw2014, \n",
    "                       d_icd_diagnoses, admissions)\n",
    "df.sample(5)\n",
    "df.shape\n",
    "df.hcc_cd_135.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Charts Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758355, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>cgid</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>label</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>dbsource</th>\n",
       "      <th>category</th>\n",
       "      <th>unitname</th>\n",
       "      <th>eventtime</th>\n",
       "      <th>hcc_cd_135</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40124</td>\n",
       "      <td>126179</td>\n",
       "      <td>279554</td>\n",
       "      <td>223761</td>\n",
       "      <td>2130-02-04 04:00:00</td>\n",
       "      <td>2130-02-04 04:35:00</td>\n",
       "      <td>19085</td>\n",
       "      <td>95.9</td>\n",
       "      <td>95.9</td>\n",
       "      <td>Temperature Fahrenheit</td>\n",
       "      <td>Temperature F</td>\n",
       "      <td>metavision</td>\n",
       "      <td>routine_vital_signs</td>\n",
       "      <td>?F</td>\n",
       "      <td>2130-02-04 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2130-02-04 02:26:00</td>\n",
       "      <td>2130-02-10 17:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>40124</td>\n",
       "      <td>126179</td>\n",
       "      <td>279554</td>\n",
       "      <td>224695</td>\n",
       "      <td>2130-02-04 04:25:00</td>\n",
       "      <td>2130-02-04 05:55:00</td>\n",
       "      <td>18999</td>\n",
       "      <td>2222221.7</td>\n",
       "      <td>2222221.7</td>\n",
       "      <td>Peak Insp. Pressure</td>\n",
       "      <td>Peak Insp. Pressure</td>\n",
       "      <td>metavision</td>\n",
       "      <td>respiratory</td>\n",
       "      <td>cmH2O</td>\n",
       "      <td>2130-02-04 04:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2130-02-04 02:26:00</td>\n",
       "      <td>2130-02-10 17:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40124</td>\n",
       "      <td>126179</td>\n",
       "      <td>279554</td>\n",
       "      <td>220210</td>\n",
       "      <td>2130-02-04 04:30:00</td>\n",
       "      <td>2130-02-04 04:43:00</td>\n",
       "      <td>21452</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Respiratory Rate</td>\n",
       "      <td>RR</td>\n",
       "      <td>metavision</td>\n",
       "      <td>respiratory</td>\n",
       "      <td>insp/min</td>\n",
       "      <td>2130-02-04 04:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2130-02-04 02:26:00</td>\n",
       "      <td>2130-02-10 17:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>40124</td>\n",
       "      <td>126179</td>\n",
       "      <td>279554</td>\n",
       "      <td>220045</td>\n",
       "      <td>2130-02-04 04:32:00</td>\n",
       "      <td>2130-02-04 04:43:00</td>\n",
       "      <td>21452</td>\n",
       "      <td>94</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Heart Rate</td>\n",
       "      <td>HR</td>\n",
       "      <td>metavision</td>\n",
       "      <td>routine_vital_signs</td>\n",
       "      <td>bpm</td>\n",
       "      <td>2130-02-04 04:32:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2130-02-04 02:26:00</td>\n",
       "      <td>2130-02-10 17:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>40124</td>\n",
       "      <td>126179</td>\n",
       "      <td>279554</td>\n",
       "      <td>220179</td>\n",
       "      <td>2130-02-04 04:32:00</td>\n",
       "      <td>2130-02-04 04:43:00</td>\n",
       "      <td>21452</td>\n",
       "      <td>163</td>\n",
       "      <td>163.0</td>\n",
       "      <td>Non Invasive Blood Pressure systolic</td>\n",
       "      <td>NBPs</td>\n",
       "      <td>metavision</td>\n",
       "      <td>routine_vital_signs</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>2130-02-04 04:32:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2130-02-04 02:26:00</td>\n",
       "      <td>2130-02-10 17:39:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id hadm_id icustay_id  itemid           charttime  \\\n",
       "0      40124  126179     279554  223761 2130-02-04 04:00:00   \n",
       "1      40124  126179     279554  224695 2130-02-04 04:25:00   \n",
       "2      40124  126179     279554  220210 2130-02-04 04:30:00   \n",
       "3      40124  126179     279554  220045 2130-02-04 04:32:00   \n",
       "4      40124  126179     279554  220179 2130-02-04 04:32:00   \n",
       "\n",
       "            storetime   cgid      value   valuenum  \\\n",
       "0 2130-02-04 04:35:00  19085       95.9       95.9   \n",
       "1 2130-02-04 05:55:00  18999  2222221.7  2222221.7   \n",
       "2 2130-02-04 04:43:00  21452         15       15.0   \n",
       "3 2130-02-04 04:43:00  21452         94       94.0   \n",
       "4 2130-02-04 04:43:00  21452        163      163.0   \n",
       "\n",
       "                                  label         abbreviation    dbsource  \\\n",
       "0                Temperature Fahrenheit        Temperature F  metavision   \n",
       "1                   Peak Insp. Pressure  Peak Insp. Pressure  metavision   \n",
       "2                      Respiratory Rate                   RR  metavision   \n",
       "3                            Heart Rate                   HR  metavision   \n",
       "4  Non Invasive Blood Pressure systolic                 NBPs  metavision   \n",
       "\n",
       "              category  unitname           eventtime  hcc_cd_135  \\\n",
       "0  routine_vital_signs        ?F 2130-02-04 04:00:00           1   \n",
       "1          respiratory     cmH2O 2130-02-04 04:25:00           1   \n",
       "2          respiratory  insp/min 2130-02-04 04:30:00           1   \n",
       "3  routine_vital_signs       bpm 2130-02-04 04:32:00           1   \n",
       "4  routine_vital_signs      mmHg 2130-02-04 04:32:00           1   \n",
       "\n",
       "            admittime           dischtime  \n",
       "0 2130-02-04 02:26:00 2130-02-10 17:39:00  \n",
       "1 2130-02-04 02:26:00 2130-02-10 17:39:00  \n",
       "2 2130-02-04 02:26:00 2130-02-10 17:39:00  \n",
       "3 2130-02-04 02:26:00 2130-02-10 17:39:00  \n",
       "4 2130-02-04 02:26:00 2130-02-10 17:39:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_clean_charts_data(chartevents, d_items, label):\n",
    "\n",
    "    # merge in labels\n",
    "    charts = chartevents.merge(d_items, how='left', on='itemid', indicator='_d_items')\n",
    "    f'charts data shape: {charts.shape}'\n",
    "    \n",
    "    if (charts._d_items != 'both').any():\n",
    "        print('merge statistics')\n",
    "        charts._d_items.value_counts()\n",
    "\n",
    "    # convert time fields to datetime\n",
    "    for col in ['charttime', 'storetime']:\n",
    "        charts[col] = pd.to_datetime(charts[col])\n",
    "\n",
    "    # use the earliest time between events that are recorded directly in the chart\n",
    "    # and events that are manually stored\n",
    "    charts['eventtime'] = charts[['charttime', 'storetime']].min(axis=1)\n",
    "    \n",
    "    # change the valuenum field to numeric in case we need it\n",
    "    charts['valuenum'] = charts['valuenum'].astype(float)\n",
    "    \n",
    "    # drop unnecessary columns\n",
    "    drop_cols = ['conceptid', 'param_type', '_d_items', 'valueuom', 'warning',\n",
    "                'error', 'resultstatus', 'stopped', 'row_id_x', 'row_id_y',\n",
    "                'linksto']\n",
    "    charts = charts.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # make this upper case to avoid issues with spelling and capitalization\n",
    "    charts['category'] = charts['category'].str.lower()\\\n",
    "                                            .str.replace('-', '')\\\n",
    "                                            .str.replace('  ', '')\\\n",
    "                                            .str.replace(' ', '_')\\\n",
    "                                            .str.replace(r\"\\'s\", '')\\\n",
    "                                            .str.replace('\\/', '_')\\\n",
    "                                            .str.replace('(', '')\\\n",
    "                                            .str.replace(')', '')\n",
    "    charts['category'] = charts['category']\n",
    "    \n",
    "    # merge in label\n",
    "    charts = charts.merge(label, how='left', on=['subject_id', 'hadm_id'])\n",
    "    return charts\n",
    "\n",
    "charts = make_clean_charts_data(chartevents, d_items, df)\n",
    "charts.shape\n",
    "charts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Investigation List**\n",
    "---\n",
    "- chronic liver disease\n",
    "- sepsis\n",
    "- mechanical ventilation\n",
    "- anemia\n",
    "- potassium\n",
    "- sodium\n",
    "\n",
    "**Done**\n",
    "- medical imaging that uses contrast dyes\n",
    "- prescriptions which can be nephrotoxins\n",
    "- low blood ph\n",
    "- hypertension\n",
    "- hematocrit\n",
    "- gender\n",
    "- age\n",
    "- ethnicity\n",
    "- creatinine increases\n",
    "- urine color\n",
    "- urine appearance\n",
    "- prior admission in 30, 60, 90, 120 days\n",
    "- prior micu icustay in 30 days\n",
    "- prior ccu icustay in 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Discovery**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrast_imaging_feature(cptevents):\n",
    "    \"\"\"cpt codes for imaging with contrast dyes\"\"\"\n",
    "    res = cptevents.loc[cptevents.cpt_cd.str.startswith('70') | \n",
    "                        cptevents.cpt_cd.str.startswith('71') |\n",
    "                        cptevents.cpt_cd.str.startswith('72') |\n",
    "                        cptevents.cpt_cd.str.startswith('73') |\n",
    "                        cptevents.cpt_cd.str.startswith('74') |\n",
    "                        cptevents.cpt_cd.str.startswith('75')]\n",
    "    radiology_cpt_codes = [\n",
    "        '74177',\n",
    "        '74160',\n",
    "        '71260',\n",
    "        '74177',\n",
    "        '73701',\n",
    "        '73201',\n",
    "        '70460',\n",
    "        '70487',\n",
    "        '70491',\n",
    "        '70481',\n",
    "        '72193',\n",
    "        '72126',\n",
    "        '72132',\n",
    "        '72129',\n",
    "        '75574',\n",
    "        '75572',\n",
    "        '70545',\n",
    "        '70548'\n",
    "    ] # codes with contrast from 2019 (i know it's not the right year)\n",
    "\n",
    "    res['ft_contrast_imaging'] = res.cpt_cd.isin(radiology_cpt_codes)*1\n",
    "    return res.groupby('hadm_id', as_index=False)['ft_contrast_imaging'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nephrotoxin_features(prescriptions, admissions):\n",
    "    \"\"\"add features for some drugs\"\"\"\n",
    "    res = prescriptions.merge(admissions, how='left', on=['hadm_id', 'subject_id'])\n",
    "    meds_list = {}\n",
    "    meds_list['antibiotics'] = ['bacitracin', \n",
    "                                'vancomycin', \n",
    "                                'amphotericin', \n",
    "                                'cephalosporin', \n",
    "                                'aminoglycoloside',\n",
    "                                'ciprofloxacin']\n",
    "    meds_list['blood_pressure'] = ['lisinopril', \n",
    "                                   'ramipril', \n",
    "                                   'metoprolol', \n",
    "                                   'candesartan', \n",
    "                                   'valsartan', \n",
    "                                   'warfarin']\n",
    "    meds_list['edema'] = ['furosemide']\n",
    "    meds_list['nsaid'] = ['ibuprofen', 'naproxen', 'ketoprofen']\n",
    "    meds_list['ulcer'] = ['cimetidine']\n",
    "    meds_list['other'] = ['propofol']\n",
    "\n",
    "    res['time_delta'] = pd.to_datetime(res.startdate) - pd.to_datetime(res.admittime)\n",
    "    def within_x_hours(data, x):\n",
    "        return data.time_delta < pd.Timedelta(x, 'hr')\n",
    "\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    # all drugs\n",
    "    drug = pd.Series([False for i in range(len(res))])\n",
    "    for med in flatten(list(meds_list.values())):\n",
    "        drug |= res.drug.str.lower().str.contains(med, na=False)\n",
    "\n",
    "    res['ft_any_nephrotoxin_rx'] = drug*1\n",
    "    for hr in [24, 48, 72]:\n",
    "        res[f'ft_any_nephrotoxin_rx_within_{hr}'] = (drug & within_x_hours(res, hr))*1\n",
    "\n",
    "    # groups of drugs\n",
    "    for group, drugs in meds_list.items():\n",
    "        drug = pd.Series([False for i in range(len(res))])\n",
    "        for med in drugs:\n",
    "            this_drug = res.drug.str.lower().str.contains(med, na=False)\n",
    "            drug |= this_drug        # add to the large list\n",
    "            res[f'ft_nephrotoxin_{med}_rx'] = this_drug*1  # make its own feature\n",
    "            for hr in [24, 48, 72]:\n",
    "                res[f'ft_nephrotoxin_{med}_rx_within_{hr}'] = (this_drug & within_x_hours(res, hr))*1\n",
    "\n",
    "        # any drug in the group\n",
    "        res[f'ft_nephrotoxin_{group}_rx'] = drug*1\n",
    "        for hr in [24, 48, 72]:\n",
    "            res[f'ft_nephrotoxin_{group}_rx_within_{hr}'] = (drug & within_x_hours(res, hr))*1\n",
    "\n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blood_ph_features(charts):\n",
    "    \"\"\"create features for the low blood ph\"\"\"\n",
    "    res = charts.loc[charts.label.str.contains('pH') | charts.label.str.contains('PH'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                      'value', 'valuenum', 'unitname']]\n",
    "    res['label'] = 'blood_ph'\n",
    "    \n",
    "    # what is low blood ph\n",
    "    lowbloodph = res.valuenum.lt(7.30)\n",
    "    \n",
    "    res['time_delta'] = res.eventtime - res.admittime    \n",
    "    def within_x_hours(data, x):\n",
    "        return data.time_delta < pd.Timedelta(x, 'hr')\n",
    "    \n",
    "    res['ft_low_blood_ph'] = lowbloodph*1\n",
    "    res['ft_low_blood_ph_within_6_hrs'] = (lowbloodph & within_x_hours(res, 6))*1\n",
    "    res['ft_low_blood_ph_within_12_hrs'] = (lowbloodph & within_x_hours(res, 12))*1\n",
    "    res['ft_low_blood_ph_within_24_hrs'] = (lowbloodph & within_x_hours(res, 24))*1\n",
    "    res['ft_low_blood_ph_within_36_hrs'] = (lowbloodph & within_x_hours(res, 36))*1\n",
    "    res['ft_low_blood_ph_within_48_hrs'] = (lowbloodph & within_x_hours(res, 48))*1\n",
    "    \n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prior_admissions(admissions, icustays):\n",
    "    \"\"\"prior admissions\"\"\"\n",
    "    # self merge\n",
    "    res = admissions.merge(admissions, how='left', on=['subject_id'], suffixes=['_first', '_second'])\n",
    "    \n",
    "    # change the datatypes\n",
    "    times = [x for x in res if 'time' in x]\n",
    "    for i in times:\n",
    "        res[i] = pd.to_datetime(res[i])\n",
    "    \n",
    "    # remove comparison with self\n",
    "    res = res.loc[res.hadm_id_first != res.hadm_id_second]\n",
    "    res = res.rename(columns={'hadm_id_first': 'hadm_id'})\n",
    "    \n",
    "    # add icu data\n",
    "    res = res.merge(icustays, how='left', left_on='hadm_id_second', right_on='hadm_id', suffixes=['', '_icu'])\n",
    "    res = pd.concat([res, pd.get_dummies(res.last_careunit.str.lower(), dtype=bool)], axis=1)\n",
    "    \n",
    "    # make features\n",
    "    prior_admission_30 = (res.admittime_second - res.dischtime_first).dt.days.lt(30)\n",
    "    prior_admission_60 = (res.admittime_second - res.dischtime_first).dt.days.lt(60)\n",
    "    prior_admission_90 = (res.admittime_second - res.dischtime_first).dt.days.lt(90)\n",
    "    prior_admission_120 = (res.admittime_second - res.dischtime_first).dt.days.lt(120)\n",
    "    \n",
    "    res['ft_prior_admission_30'] = prior_admission_30*1\n",
    "    res['ft_prior_admission_60'] = prior_admission_60*1\n",
    "    res['ft_prior_admission_90'] = prior_admission_90*1\n",
    "    res['ft_prior_admission_120'] = prior_admission_120*1\n",
    "    \n",
    "    res['ft_avg_icu_los_within_30'] = np.where(prior_admission_30, res.los.astype(float), np.nan)\n",
    "    res['ft_micu_within_30'] = (res.micu & prior_admission_30) * 1\n",
    "    res['ft_ccu_within_30'] = (res.ccu & prior_admission_30) * 1\n",
    "    \n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hcc_feature(hccs, label='', rename_as=None):\n",
    "    \"\"\"select an hcc feature\"\"\"\n",
    "    cols = [x for x in hccs if 'hcc_' in x]\n",
    "    if label:\n",
    "        drop_cols = [x for x in cols if label not in x]\n",
    "        hccs = hccs.drop(drop_cols, axis=1)\n",
    "    \n",
    "    if rename_as:\n",
    "        assert isinstance(rename_as, str)\n",
    "        hccs = hccs.rename(columns={'hcc_cd' + label: rename_as})\n",
    "    return hccs.drop('subject_id', axis=1)\n",
    "    \n",
    "def create_hcc_labeled_dataset(diagnoses, icdxw):\n",
    "    \"\"\"take the diagnoses dataframe and create the beginning of \n",
    "    a labeled dataset\"\"\"\n",
    "    merged = pd.merge(diagnoses, icdxw, how='left', \n",
    "                      left_on='icd9_code', right_on='icd', \n",
    "                      indicator='_hcc_merge', validate='m:1')\n",
    "            \n",
    "    # remove them from df and make final labeled dataframe\n",
    "    merged = pd.concat([merged, \n",
    "                        pd.get_dummies(merged.hcc, prefix='hcc_cd')], axis=1)\n",
    "    cols = [x for x in merged if 'hcc_cd' in x]\n",
    "    data = merged.groupby(['hadm_id', 'subject_id'], as_index=False)[cols].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypertensive_features(charts):\n",
    "    \"\"\"check the hypertensive status\"\"\"\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('diastolic'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                      'value', 'valuenum', 'unitname']]\n",
    "    res = res.loc[~res.label.str.lower().str.contains('unloading')] # remove the apache\n",
    "    res = res.loc[~res.label.str.lower().str.contains('pulmonary')] # remove the apache\n",
    "    res = res.loc[~res.label.str.lower().str.contains('pap')] # remove the apache\n",
    "    res.label = 'diastolic_blood_pressure'\n",
    "    \n",
    "    res2 = charts.loc[charts.label.str.lower().str.contains('systolic'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                      'value', 'valuenum', 'unitname']]\n",
    "    res2 = res2.loc[~res2.label.str.lower().str.contains('unloading')] # remove the apache\n",
    "    res2 = res2.loc[~res2.label.str.lower().str.contains('pulmonary')] # remove the apache\n",
    "    res2 = res2.loc[~res2.label.str.lower().str.contains('pap')] # remove the apache\n",
    "    res2.label = 'systolic_blood_pressure'\n",
    "    \n",
    "    # create combined events\n",
    "    data = res2.merge(res, how='outer', on=['hadm_id', 'eventtime'], indicator=True, \n",
    "                 suffixes=['_systolic', '_diastolic'])\n",
    "    data = data.loc[data._merge == 'both'].drop('_merge', axis=1)\n",
    "    \n",
    "    # delete stuff to clear memory\n",
    "    del res\n",
    "    del res2\n",
    "    \n",
    "    # make features\n",
    "    elevated = data.valuenum_systolic.between(120, 129) & data.valuenum_diastolic.lt(80)\n",
    "    hbp_stg_1 = data.valuenum_systolic.between(130, 139) | data.valuenum_diastolic.between(80, 89)\n",
    "    hbp_stg_2 = data.valuenum_systolic.between(140, 179) | data.valuenum_diastolic.between(90, 119)\n",
    "    crisis = data.valuenum_systolic.gt(180) | data.valuenum_diastolic.gt(120)\n",
    "    \n",
    "    # hours since admission\n",
    "    data['time_delta'] = data.eventtime - data.admittime_systolic\n",
    "    \n",
    "    def within_x_hours(data, x):\n",
    "        return data.time_delta < pd.Timedelta(x, 'hr')\n",
    "    \n",
    "    data['ft_elevated_bp'] = elevated*1\n",
    "    data['ft_hbp_stg_1'] = hbp_stg_1*1\n",
    "    data['ft_hbp_stg_2'] = hbp_stg_2*1\n",
    "    data['ft_hbp_crisis'] = crisis*1\n",
    "    \n",
    "    data['ft_hbp_stg_2_within_6_hours'] = (hbp_stg_2 & within_x_hours(data, 6)) * 1\n",
    "    data['ft_hbp_stg_2_within_12_hours'] = (hbp_stg_2 & within_x_hours(data, 12)) * 1\n",
    "    data['ft_hbp_stg_2_within_24_hours'] = (hbp_stg_2 & within_x_hours(data, 24)) * 1\n",
    "    data['ft_hbp_stg_2_within_36_hours'] = (hbp_stg_2 & within_x_hours(data, 36)) * 1\n",
    "    data['ft_hbp_stg_2_within_48_hours'] = (hbp_stg_2 & within_x_hours(data, 48)) * 1\n",
    "    \n",
    "    features = [x for x in data if 'ft_' in x]\n",
    "    data = data.groupby('hadm_id', as_index=False)[features].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hematocrit_features(charts, pt):\n",
    "    \"\"\" check hematocrit and hemoglobin levels for anemia \"\"\"\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('hematocrit'), \n",
    "                     ['hadm_id', 'eventtime', 'admittime', 'label', 'value', 'valuenum', 'unitname']]\n",
    "    res = res.loc[~res.label.str.lower().str.contains('apache')] # remove the apache\n",
    "\n",
    "    # add the gender\n",
    "    res = res.merge(pt[['hadm_id', 'ft_gender']], how='left', on='hadm_id')\n",
    "\n",
    "    # clean the label name\n",
    "    res['label'] = 'hematocrit'\n",
    "\n",
    "    # add features\n",
    "    male = res.ft_gender == 1\n",
    "    male_range = (42, 50)\n",
    "    female_range = (37, 47)\n",
    "    above_normal = (male & (res.valuenum > male_range[1])) | (~male & (res.valuenum > female_range[1]))\n",
    "    below_normal = (male & (res.valuenum < male_range[0])) | (~male & (res.valuenum < female_range[0]))\n",
    "    way_below_normal = res.valuenum < 20\n",
    "\n",
    "    res['ft_avg_hematocrit'] = res.valuenum\n",
    "    res['ft_above_normal_hematocrit'] = above_normal*1\n",
    "    res['ft_below_normal_hematocrit'] = below_normal*1\n",
    "    res['ft_way_below_normal_hematocrit'] = way_below_normal*1\n",
    "    res = res.drop('ft_gender', axis=1)\n",
    "    \n",
    "    agg = {'ft_avg_hematocrit': 'mean',\n",
    "          'ft_above_normal_hematocrit': 'max',\n",
    "          'ft_below_normal_hematocrit': 'max',\n",
    "          'ft_way_below_normal_hematocrit': 'max'}\n",
    "\n",
    "    return res.groupby('hadm_id', as_index=False).agg(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demographics_features(admissions, patients):\n",
    "    \"\"\"check admission information and patient demographics\"\"\"\n",
    "    pt = admissions.merge(patients, how='left', on='subject_id')\n",
    "\n",
    "    # convert data types\n",
    "    pt['dob'] = pd.to_datetime(pt.dob)\n",
    "    pt['admittime'] = pd.to_datetime(pt.admittime)\n",
    "\n",
    "    # remap gender as a binary variable\n",
    "    pt['ft_gender'] = pt.gender.map({'F': 0, 'M': 1})\n",
    "\n",
    "    # create an age feature\n",
    "    pt['ft_age'] = pt.admittime.sub(pt.dob, axis=0).dt.days / 365.25\n",
    "    pt['ft_age'] = np.where(pt.ft_age < -1, np.nan, pt.ft_age) \n",
    "    # null out fake dobs, they don't give us information\n",
    "\n",
    "    # admit type feature\n",
    "    admit_type = pd.concat([pt.hadm_id, \n",
    "                            pd.get_dummies(pt['admission_type'].str.lower(),\n",
    "                                        prefix='ft_admit_type')], axis=1)\n",
    "\n",
    "    # ethnicity feature\n",
    "    ethnicity = pd.concat([pt.hadm_id, \n",
    "                           pd.get_dummies(pt['ethnicity'].str.lower()\n",
    "                                            .str.replace('/', '_')\n",
    "                                            .str.replace(' ', '_'), \n",
    "                                            prefix='ft_race')], axis=1)\n",
    "    \n",
    "    data = pt[['hadm_id', 'ft_age', 'ft_gender']].merge(admit_type, \n",
    "                                                        how='left', on='hadm_id')\n",
    "    data = data.merge(ethnicity, how='left', on='hadm_id')\n",
    "    agg_dict = {'ft_age': 'mean', 'ft_gender': 'first'}\n",
    "    agg_dict.update({k:'max' for k in admit_type if k != 'hadm_id'})\n",
    "    agg_dict.update({k:'max' for k in ethnicity if k != 'hadm_id'})\n",
    "    \n",
    "    return data.groupby('hadm_id', as_index=False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_creatinine_features(charts, test=False):\n",
    "\n",
    "    # make a dataframe of just creatinine data\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('creatin'), \n",
    "               ['hadm_id', 'eventtime', 'admittime', 'label', \n",
    "                'value', 'valuenum', 'unitname']]\n",
    "    \n",
    "    # drop crazy values\n",
    "    res = res.loc[res.valuenum <= 11]\n",
    "    \n",
    "    # sort by hospital admission and event time\n",
    "    res = res.sort_values(['hadm_id', 'eventtime']).reset_index(drop=True)\n",
    "\n",
    "    # get the value of the old test and compare to current test\n",
    "    res['value_of_previous_test'] = np.where(\n",
    "        res.hadm_id == res.hadm_id.shift(1),\n",
    "        res.valuenum.shift(1), res.valuenum)\n",
    "    res['delta'] = res.valuenum - res.value_of_previous_test\n",
    "\n",
    "    # get time previous test was administered and compare to current time\n",
    "    res['time_of_previous_test'] = np.where(\n",
    "        res.hadm_id == res.hadm_id.shift(1), \n",
    "        res.eventtime.shift(1), res.eventtime)\n",
    "    res['delta_time'] = res.eventtime - res.time_of_previous_test\n",
    "\n",
    "    # check if time is within a certain range\n",
    "    res['within_48'] = res.delta_time <= pd.Timedelta(48, 'h')\n",
    "    res['baseline_creat'] = res.groupby('hadm_id')['valuenum'].transform('first')\n",
    "\n",
    "    # make features\n",
    "    res['ft_creatinine_increase_within_48'] = ((res.delta >= 0.3) & res.within_48)*1\n",
    "    res['ft_creatinine_increase_from_baseline'] = (res.valuenum >= 1.5*res.baseline_creat)*1\n",
    "    res['ft_baseline_creat_gt_1'] = (res.baseline_creat > 1) * 1\n",
    "    res['ft_avg_creatinine'] = res.valuenum\n",
    "\n",
    "    if test:\n",
    "        return res.loc[res.groupby('hadm_id')\\\n",
    "                       ['ft_creatinine_increase_within_48'].transform('max') == 1, \n",
    "                        ['hadm_id', 'valuenum', 'delta', 'delta_time',\n",
    "                         'baseline_creat', \n",
    "                         'ft_creatinine_increase_within_48', \n",
    "                         'ft_creatinine_increase_from_baseline',\n",
    "                         'ft_baseline_creat_gt_1']]\n",
    "    \n",
    "    features = [x for x in res if 'ft_' in x]\n",
    "    return res.groupby('hadm_id', as_index=False)[features]\\\n",
    "              .agg({'ft_creatinine_increase_within_48': 'max',\n",
    "                    'ft_creatinine_increase_from_baseline': 'max',\n",
    "                    'ft_baseline_creat_gt_1': 'max',\n",
    "                    'ft_avg_creatinine': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_urine_features(charts):\n",
    "\n",
    "    res = charts.loc[charts.label.str.lower().str.contains('urine'), \n",
    "               ['hadm_id', 'eventtime', 'admittime', 'label', 'value', 'valuenum', 'unitname']]\n",
    "\n",
    "    # clean the label column\n",
    "    res['label'] = res.label.str.replace('[', '').str.replace(']', '')\n",
    "\n",
    "    # urine color\n",
    "    label = 'Urine Color'\n",
    "    color = res.loc[res.label == label]\n",
    "    color = pd.concat([color.hadm_id, pd.get_dummies(color.value.str.lower(), \n",
    "                                                 prefix=('ft_' + label.lower().replace(' ', '_')))],\n",
    "                  axis=1)\n",
    "\n",
    "    # urine appearance\n",
    "    label = 'Urine Appearance'\n",
    "    appearance = res.loc[res.label == label]\n",
    "    appearance = pd.concat([appearance.hadm_id, pd.get_dummies(appearance.value.str.lower(), \n",
    "                                                           prefix=('ft' + label.lower().replace(' ', '_')))],\n",
    "                  axis=1)\n",
    "    \n",
    "    data = color.merge(appearance, how='left', on='hadm_id')\n",
    "    data = data.groupby('hadm_id', as_index=False)[[x for x in data if 'ft_' in x]].max()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Feature Creation**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_features = create_demographics_features(admissions, patients)\n",
    "creatinine_features = create_creatinine_features(charts)\n",
    "urine_features = create_urine_features(charts)\n",
    "hematocrit_features = create_hematocrit_features(charts, demographic_features)\n",
    "hypertensive_feature = create_hypertensive_features(charts)\n",
    "hcc_labeled_data = create_hcc_labeled_dataset(diagnoses_icd, icd2hccxw2014)\n",
    "diabetes_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_19', rename_as='hcc_cd_19_dbtes_wo_comp')\n",
    "ckd5_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_136', rename_as='hcc_cd_136_ckd_stg_5')\n",
    "ckd4_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_137', rename_as='hcc_cd_137_ckd_stg_4')\n",
    "chf_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_85', rename_as='hcc_cd_85_chf')\n",
    "vascular_disease_hcc_feature = create_hcc_feature(hcc_labeled_data, label='_108', rename_as='hcc_cd_108_vascular')\n",
    "prior_admission_features = create_prior_admissions(admissions, icustays)\n",
    "blood_ph_features = create_blood_ph_features(charts)\n",
    "nephrotoxin_features = add_nephrotoxin_features(prescriptions, admissions)\n",
    "contrast_imaging_feature = create_contrast_imaging_feature(cptevents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(feature_list):\n",
    "    return functools.reduce(lambda x,y: pd.merge(x,y, how='outer', on='hadm_id'), feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    df.drop(['subject_id', 'admittime', 'dischtime'], axis=1),\n",
    "    demographic_features,\n",
    "    creatinine_features,\n",
    "    urine_features,\n",
    "    hematocrit_features,\n",
    "    hypertensive_feature,\n",
    "    diabetes_hcc_feature,\n",
    "    ckd4_hcc_feature,\n",
    "    ckd5_hcc_feature,\n",
    "    chf_hcc_feature,\n",
    "    vascular_disease_hcc_feature,\n",
    "    prior_admission_features,\n",
    "    blood_ph_features,\n",
    "    nephrotoxin_features,\n",
    "    contrast_imaging_feature\n",
    "]\n",
    "\n",
    "data = merge_features(features)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
